{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prisci723/InteligenciaArtificial1/blob/main/Laboratorio%205%20Redes%20neuronales/Lab5_1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCQdjXpNtha3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5185c571-ac64-4820-f587-a2ab99ccd180"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qo5rLIHy91nO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Información sobre el dataset\n",
        "\n",
        "https://archive.ics.uci.edu/dataset/31/covertype\n",
        "\n",
        "El siguiente dataset trata sobre el tipo de covertura de un bosque, cuenta con los datos cartográficos de bosques, recolectados por el gobierno de Estados Unidos, cuenta con las siguientes variables:\n",
        "* X1\tElevación en metros\n",
        "* X2\tAspecto\n",
        "* X3\tPendiente\n",
        "* X4\tDistancia_horizontal_a_hidrología\n",
        "* X5\tDistancia_vertical_a_hidrología\n",
        "* X6\tDistancia_horizontal_a_las_carreteras\n",
        "* X7\tsombreado_9am\n",
        "* X8\tHillshade_mediodía\n",
        "* X9\tsombreado_3pm\n",
        "* X10\tDistancia_horizontal_a_puntos_de_fuego\n",
        "* X11\tDesignación de área silvestre (clasificación)\n",
        "* X12\tDesignación de área silvestre Clasificación\n",
        "* X13\tDesignación de área silvestre Clasificación\n",
        "* X14\tDesignación de área silvestre Clasificación\n",
        "* [X15 - X55]\tDesignación del tipo de suelo 40 columnas de clasificación\n",
        "\n",
        "\n",
        "Target:\n",
        "\n",
        "y: Designación del tipo de cubierta forestal (1-7)\n",
        "\n",
        "\n",
        "Con la siguiente inforamción se procede a la limpieza del dataset utilizando pandas"
      ],
      "metadata": {
        "id": "WVZYM15a9ydM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "6kPiR5MSxC7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.read_csv(\"/content/gdrive/MyDrive/Machine learning/Datasets/covtype.csv\", sep=\",\")\n",
        "print(dataframe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEJm27XTxCP_",
        "outputId": "dbb35004-a140-4e60-fed5-35fbf2dae7fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        2596   51   3  258    0   510  221  232  148  6279  ...  0.34  0.35  \\\n",
            "0       2590   56   2  212   -6   390  220  235  151  6225  ...     0     0   \n",
            "1       2804  139   9  268   65  3180  234  238  135  6121  ...     0     0   \n",
            "2       2785  155  18  242  118  3090  238  238  122  6211  ...     0     0   \n",
            "3       2595   45   2  153   -1   391  220  234  150  6172  ...     0     0   \n",
            "4       2579  132   6  300  -15    67  230  237  140  6031  ...     0     0   \n",
            "...      ...  ...  ..  ...  ...   ...  ...  ...  ...   ...  ...   ...   ...   \n",
            "581006  2396  153  20   85   17   108  240  237  118   837  ...     0     0   \n",
            "581007  2391  152  19   67   12    95  240  237  119   845  ...     0     0   \n",
            "581008  2386  159  17   60    7    90  236  241  130   854  ...     0     0   \n",
            "581009  2384  170  15   60    5    90  230  245  143   864  ...     0     0   \n",
            "581010  2383  165  13   60    4    67  231  244  141   875  ...     0     0   \n",
            "\n",
            "        0.36  0.37  0.38  0.39  0.40  0.41  0.42  5  \n",
            "0          0     0     0     0     0     0     0  5  \n",
            "1          0     0     0     0     0     0     0  2  \n",
            "2          0     0     0     0     0     0     0  2  \n",
            "3          0     0     0     0     0     0     0  5  \n",
            "4          0     0     0     0     0     0     0  2  \n",
            "...      ...   ...   ...   ...   ...   ...   ... ..  \n",
            "581006     0     0     0     0     0     0     0  3  \n",
            "581007     0     0     0     0     0     0     0  3  \n",
            "581008     0     0     0     0     0     0     0  3  \n",
            "581009     0     0     0     0     0     0     0  3  \n",
            "581010     0     0     0     0     0     0     0  3  \n",
            "\n",
            "[581011 rows x 55 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comprobados si existen valores nulos**"
      ],
      "metadata": {
        "id": "RLXBPtU8_xBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataframe.isnull().any())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk0fplgxw_iR",
        "outputId": "23e0ad50-1f2a-4925-8622-942135877164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2596    False\n",
            "51      False\n",
            "3       False\n",
            "258     False\n",
            "0       False\n",
            "510     False\n",
            "221     False\n",
            "232     False\n",
            "148     False\n",
            "6279    False\n",
            "1       False\n",
            "0.1     False\n",
            "0.2     False\n",
            "0.3     False\n",
            "0.4     False\n",
            "0.5     False\n",
            "0.6     False\n",
            "0.7     False\n",
            "0.8     False\n",
            "0.9     False\n",
            "0.10    False\n",
            "0.11    False\n",
            "0.12    False\n",
            "0.13    False\n",
            "0.14    False\n",
            "0.15    False\n",
            "0.16    False\n",
            "0.17    False\n",
            "0.18    False\n",
            "0.19    False\n",
            "0.20    False\n",
            "0.21    False\n",
            "0.22    False\n",
            "0.23    False\n",
            "0.24    False\n",
            "0.25    False\n",
            "0.26    False\n",
            "0.27    False\n",
            "0.28    False\n",
            "0.29    False\n",
            "0.30    False\n",
            "0.31    False\n",
            "1.1     False\n",
            "0.32    False\n",
            "0.33    False\n",
            "0.34    False\n",
            "0.35    False\n",
            "0.36    False\n",
            "0.37    False\n",
            "0.38    False\n",
            "0.39    False\n",
            "0.40    False\n",
            "0.41    False\n",
            "0.42    False\n",
            "5       False\n",
            "dtype: bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comprobados si existen valores no numéricos dentro del dataset**"
      ],
      "metadata": {
        "id": "fXfouUnt_2v5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar si hay valores no numéricos en las columnas excepto la fecha[columnas_numericas]\n",
        "non_numeric_columns = dataframe.apply(lambda x: pd.to_numeric(x, errors='coerce')).isnull().any()\n",
        "print(\"Valores no numéricos en las columnas:\")\n",
        "print(non_numeric_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8WDvir1xwc1",
        "outputId": "995c69c5-4154-4802-bafa-d920b240e5a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valores no numéricos en las columnas:\n",
            "2596    False\n",
            "51      False\n",
            "3       False\n",
            "258     False\n",
            "0       False\n",
            "510     False\n",
            "221     False\n",
            "232     False\n",
            "148     False\n",
            "6279    False\n",
            "1       False\n",
            "0.1     False\n",
            "0.2     False\n",
            "0.3     False\n",
            "0.4     False\n",
            "0.5     False\n",
            "0.6     False\n",
            "0.7     False\n",
            "0.8     False\n",
            "0.9     False\n",
            "0.10    False\n",
            "0.11    False\n",
            "0.12    False\n",
            "0.13    False\n",
            "0.14    False\n",
            "0.15    False\n",
            "0.16    False\n",
            "0.17    False\n",
            "0.18    False\n",
            "0.19    False\n",
            "0.20    False\n",
            "0.21    False\n",
            "0.22    False\n",
            "0.23    False\n",
            "0.24    False\n",
            "0.25    False\n",
            "0.26    False\n",
            "0.27    False\n",
            "0.28    False\n",
            "0.29    False\n",
            "0.30    False\n",
            "0.31    False\n",
            "1.1     False\n",
            "0.32    False\n",
            "0.33    False\n",
            "0.34    False\n",
            "0.35    False\n",
            "0.36    False\n",
            "0.37    False\n",
            "0.38    False\n",
            "0.39    False\n",
            "0.40    False\n",
            "0.41    False\n",
            "0.42    False\n",
            "5       False\n",
            "dtype: bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataframe['5'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1GfZWkyygs3",
        "outputId": "12767cc3-66bb-4478-e7ea-38e5f0088b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 2 1 7 3 6 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como el dataset está limpio y no posee inconsistencias, el modelo comienza a ser aplicado"
      ],
      "metadata": {
        "id": "t8iPH9xOAQKN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aplicación del modelo"
      ],
      "metadata": {
        "id": "JxcYJRa9AaJ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se importan las librerías necesarias para ser utilizadas por la red neuronal"
      ],
      "metadata": {
        "id": "_lg77bmkAooo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stUHtyXwtUTc"
      },
      "source": [
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from scipy import optimize\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdNP-OaBtlmp"
      },
      "source": [
        "import sys\n",
        "\n",
        "sys.path.insert(0, '/content/gdrive/MyDrive/Colab Notebooks/machine learning/datasets')\n",
        "sys.path.insert(1, '/content/gdrive/MyDrive/Colab Notebooks/machine learning/03 redes neuronales')\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset es importado"
      ],
      "metadata": {
        "id": "rMwe_QBhA5wg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1urWqmYvPE3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bc6d48e4-ddae-4130-affb-d6b28e2a45dd"
      },
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copy('/content/gdrive/MyDrive/Machine learning/Datasets/covtype.csv', '/content/data')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPKROwkOtpkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46784aca-4024-480f-bed8-c5c911d2dcf9"
      },
      "source": [
        "\n",
        "data = np.loadtxt('/content/gdrive/MyDrive/Machine learning/Datasets/covtype.csv', delimiter=',')\n",
        "\n",
        "# X y Y son extraidos del dataset\n",
        "X, y = data[:, 0:-1], data[:,-1]\n",
        "\n",
        "#Los valores del target son comprobados que sean enteros y también garantiza de que sea un array de una sola dimensión\n",
        "y = np.array([int(e) for e in y])\n",
        "print(y.shape)\n",
        "y = np.squeeze(y)\n",
        "\n",
        "#Los valores de y cambian para que comienzen en 0\n",
        "y[y == 1] = 0\n",
        "y[y == 2] = 1\n",
        "y[y == 3] = 2\n",
        "y[y == 4] = 3\n",
        "y[y == 5] = 4\n",
        "y[y == 6] = 5\n",
        "y[y == 7] = 6\n",
        "\n",
        "#Obtenemos el 80% de los datos y separamos el entrenamiento de la prueba\n",
        "test = X.shape[0]*0.8\n",
        "test = round(test)\n",
        "\n",
        "Xp= X[test:,:]\n",
        "X = X[:test,:]\n",
        "\n",
        "yp = y[test:]\n",
        "y = y[:test]\n",
        "\n",
        "#Se imprime el tamaño de los arrays separados\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(Xp.shape)\n",
        "print(yp.shape)\n",
        "\n",
        "print(y)\n",
        "print(yp)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(581012,)\n",
            "(464810, 54)\n",
            "(464810,)\n",
            "(116202, 54)\n",
            "(116202,)\n",
            "[4 4 1 ... 0 1 1]\n",
            "[1 1 1 ... 2 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalización de los datos**\n",
        "\n",
        "Los datos son normalizados ya que se encuentran en distintas escalas, y también a que se ocupen menos recursos al momento de su optimización."
      ],
      "metadata": {
        "id": "Ffq-aButCE4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def  featureNormalize(X):\n",
        "    X_norm = X.copy()\n",
        "    mu = np.zeros(X.shape[1])\n",
        "    sigma = np.zeros(X.shape[1])\n",
        "\n",
        "    mu = np.mean(X, axis = 0)\n",
        "    sigma = np.std(X, axis = 0)\n",
        "    X_norm = (X - mu) / sigma\n",
        "\n",
        "    return X_norm, mu, sigma"
      ],
      "metadata": {
        "id": "Bc5mxtZXyicE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, mu, sigma = featureNormalize(X)\n",
        "\n",
        "print(X)\n",
        "print('Media calculada:', mu)\n",
        "print('Desviación estandar calculada:', sigma)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L36E5ABiy9he",
        "outputId": "d80fb251-845d-4789-ec0f-794ec55d0e25"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.22267023 -0.90636509 -1.4244481  ... -0.16428962 -0.14043752\n",
            "  -0.10991019]\n",
            " [-1.24422982 -0.86153978 -1.55741491 ... -0.16428962 -0.14043752\n",
            "  -0.10991019]\n",
            " [-0.47527104 -0.11743951 -0.62664724 ... -0.16428962 -0.14043752\n",
            "  -0.10991019]\n",
            " ...\n",
            " [ 0.13199081  1.60385266 -0.49368044 ... -0.16428962 -0.14043752\n",
            "  -0.10991019]\n",
            " [ 0.13558407  1.57695747 -0.62664724 ... -0.16428962 -0.14043752\n",
            "  -0.10991019]\n",
            " [ 0.14995713  1.43351645 -0.22774682 ... -0.16428962 -0.14043752\n",
            "  -0.10991019]]\n",
            "Media calculada: [2.93626717e+03 1.52099686e+02 1.37128095e+01 2.62642127e+02\n",
            " 4.50795723e+01 2.50147360e+03 2.12845328e+02 2.23118352e+02\n",
            " 1.41790030e+02 2.05627125e+03 5.51618941e-01 1.62862245e-03\n",
            " 3.67218864e-01 7.95335729e-02 6.52094404e-03 1.05806674e-02\n",
            " 5.44523569e-03 1.63916439e-02 3.43581248e-03 1.41455649e-02\n",
            " 2.25898754e-04 3.85103591e-04 2.46767496e-03 5.79355005e-02\n",
            " 1.77577935e-02 6.44801102e-02 2.64559713e-02 8.08932682e-04\n",
            " 6.45425012e-06 5.44523569e-03 6.87162497e-03 3.93494116e-03\n",
            " 6.70166305e-03 1.83903100e-02 1.80288720e-03 4.55777630e-02\n",
            " 9.00346378e-02 2.91301822e-02 2.15141671e-06 4.97837826e-03\n",
            " 3.22712506e-05 2.03524021e-03 2.45887567e-01 6.39831329e-02\n",
            " 4.25227512e-02 8.53122781e-02 5.86949506e-02 1.51890020e-03\n",
            " 1.64368236e-03 2.56018588e-04 6.41122179e-04 2.62817065e-02\n",
            " 1.93412362e-02 1.19360599e-02]\n",
            "Desviación estandar calculada: [2.78298401e+02 1.11544108e+02 7.52067383e+00 2.07155309e+02\n",
            " 5.58593050e+01 1.60911795e+03 2.66284567e+01 1.95808525e+01\n",
            " 3.77434324e+01 1.38824653e+03 4.97328347e-01 4.03233188e-02\n",
            " 4.82046854e-01 2.70569739e-01 8.04886410e-02 1.02316748e-01\n",
            " 7.35906590e-02 1.26976210e-01 5.85150209e-02 1.18090930e-01\n",
            " 1.50282309e-02 1.96202774e-02 4.96143683e-02 2.33621442e-01\n",
            " 1.32069884e-01 2.45606241e-01 1.60486924e-01 2.84302358e-02\n",
            " 2.54051343e-03 7.35906590e-02 8.26099615e-02 6.26055700e-02\n",
            " 8.15889132e-02 1.34358128e-01 4.24221263e-02 2.08567568e-01\n",
            " 2.86231378e-01 1.68171385e-01 1.46676927e-03 7.03817733e-02\n",
            " 5.68068739e-03 4.50677047e-02 4.30612205e-01 2.44722887e-01\n",
            " 2.01778509e-01 2.79345831e-01 2.35052874e-01 3.89434608e-02\n",
            " 4.05090197e-02 1.59985325e-02 2.53122725e-02 1.59971805e-01\n",
            " 1.37721287e-01 1.08598298e-01]\n",
            "[[-1.22267023 -0.90636509 -1.4244481  ... -0.16428962 -0.14043752\n",
            "  -0.10991019]\n",
            " [-1.24422982 -0.86153978 -1.55741491 ... -0.16428962 -0.14043752\n",
            "  -0.10991019]\n",
            " [-0.47527104 -0.11743951 -0.62664724 ... -0.16428962 -0.14043752\n",
            "  -0.10991019]\n",
            " ...\n",
            " [ 0.13199081  1.60385266 -0.49368044 ... -0.16428962 -0.14043752\n",
            "  -0.10991019]\n",
            " [ 0.13558407  1.57695747 -0.62664724 ... -0.16428962 -0.14043752\n",
            "  -0.10991019]\n",
            " [ 0.14995713  1.43351645 -0.22774682 ... -0.16428962 -0.14043752\n",
            "  -0.10991019]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta parte se establecerá las capas y la cantidad de entradas y como estarán configuradas para aplicar el modelo."
      ],
      "metadata": {
        "id": "vclzA19HCu_v"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN2IfP_5vz8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f9503bd-8405-4adc-d2ab-cc5b9ecaaa69"
      },
      "source": [
        "# Configurando parametros necesario\n",
        "input_layer_size  = 54  # 54 features en total\n",
        "hidden_layer_size = 30   # 30 perceptrones en la capa oculta\n",
        "num_labels = 7          # La salida son 7 tipos del 0 al 6\n",
        "\n",
        "pesos = {}\n",
        "pesos['Theta1'] = np.random.rand(30, 55)\n",
        "pesos['Theta2'] = np.random.rand(7, 31)\n",
        "\n",
        "Theta1, Theta2 = pesos['Theta1'], pesos['Theta2']\n",
        "\n",
        "print(Theta1.ravel().shape)\n",
        "print(Theta2.ravel().shape)\n",
        "\n",
        "nn_params = np.concatenate([Theta1.ravel(), Theta2.ravel()])\n",
        "print(nn_params.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1650,)\n",
            "(217,)\n",
            "(1867,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función de activación es establecida, también el gradiente de la sigmoide"
      ],
      "metadata": {
        "id": "QK50XStsDLsq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYkAveQh0e87"
      },
      "source": [
        "def sigmoid(z):\n",
        "    \"\"\"\n",
        "    Computes the sigmoid of z.\n",
        "    \"\"\"\n",
        "    return 1.0 / (1.0 + np.exp(-z))\n",
        "\n",
        "\n",
        "def sigmoidGradient(z):\n",
        "\n",
        "    g = np.zeros(z.shape)\n",
        "\n",
        "    g = sigmoid(z) * (1 - sigmoid(z))\n",
        "\n",
        "    return g"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La siguiente función es la más importante del modelo, ya que en esta parte es que se calculará el costo y el gradiente para ser aplicados en el modelo y así poder obtener la salida de la red neuronal.\n",
        "\n",
        "Comienza con el cálculo de capa por capa."
      ],
      "metadata": {
        "id": "FJRJOvwkDZJN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aevzq-rt0vKn"
      },
      "source": [
        "def nnCostFunction(nn_params,\n",
        "                   input_layer_size,\n",
        "                   hidden_layer_size,\n",
        "                   num_labels,\n",
        "                   X, y, lambda_= 0.0):\n",
        "\n",
        "    #Theta1 y Theta2 cambian de dimensión para poder se utilizados\n",
        "    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n",
        "                        (hidden_layer_size, (input_layer_size + 1)))\n",
        "\n",
        "    Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n",
        "                        (num_labels, (hidden_layer_size + 1)))\n",
        "\n",
        "    m = y.size\n",
        "\n",
        "    J = 0\n",
        "    Theta1_grad = np.zeros(Theta1.shape)\n",
        "    Theta2_grad = np.zeros(Theta2.shape)\n",
        "    #Fin de la redimensionamiento\n",
        "    #Los pesos son calculados para cada capa\n",
        "    a1 = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
        "\n",
        "    a2 = sigmoid(a1.dot(Theta1.T))\n",
        "    a2 = np.concatenate([np.ones((a2.shape[0], 1)), a2], axis=1)\n",
        "\n",
        "    a3 = sigmoid(a2.dot(Theta2.T))\n",
        "\n",
        "\n",
        "    y_matrix = y.reshape(-1)\n",
        "\n",
        "    y_matrix = np.eye(num_labels)[y_matrix]\n",
        "\n",
        "\n",
        "    temp1 = Theta1\n",
        "    temp2 = Theta2\n",
        "\n",
        "    # La regularización es añadida a la función de costo que BCE\n",
        "\n",
        "    reg_term = (lambda_ / (2 * m)) * (np.sum(np.square(temp1[:, 1:])) + np.sum(np.square(temp2[:, 1:])))\n",
        "\n",
        "    J = (-1 / m) * np.sum((np.log(a3) * y_matrix) + np.log(1 - a3) * (1 - y_matrix)) + reg_term\n",
        "\n",
        "    # Backpropogation\n",
        "\n",
        "    delta_3 = a3 - y_matrix\n",
        "    delta_2 = delta_3.dot(Theta2)[:, 1:] * sigmoidGradient(a1.dot(Theta1.T))\n",
        "\n",
        "    Delta1 = delta_2.T.dot(a1)\n",
        "    Delta2 = delta_3.T.dot(a2)\n",
        "\n",
        "    # La regularización es añadida al descenso de gradiente\n",
        "\n",
        "    Theta1_grad = (1 / m) * Delta1\n",
        "    Theta1_grad[:, 1:] = Theta1_grad[:, 1:] + (lambda_ / m) * Theta1[:, 1:]\n",
        "\n",
        "    Theta2_grad = (1 / m) * Delta2\n",
        "    Theta2_grad[:, 1:] = Theta2_grad[:, 1:] + (lambda_ / m) * Theta2[:, 1:]\n",
        "\n",
        "\n",
        "    grad = np.concatenate([Theta1_grad.ravel(), Theta2_grad.ravel()])\n",
        "    return J, grad"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demostración e inicialización de los parametros que vayan a ser aplicados dentro de la red neuronal"
      ],
      "metadata": {
        "id": "FTYjAt3hFnY_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4TjzE2h3BqL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2697f923-bae4-4ec1-f2e5-215d9549a964"
      },
      "source": [
        "lambda_ = 0\n",
        "J, _ = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_)\n",
        "print('Costo en parametros (cargado de ex4weights): %.6f ' % J)\n",
        "print('El costo debe esta cercano a               : 0.287629')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Costo en parametros (cargado de ex4weights): 47.894055 \n",
            "El costo debe esta cercano a               : 0.287629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnKgJRZq-x3U"
      },
      "source": [
        "def randInitializeWeights(L_in, L_out, epsilon_init=0.12):\n",
        "\n",
        "    W = np.zeros((L_out, 1 + L_in))\n",
        "    W = np.random.rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init\n",
        "\n",
        "    return W"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znk_8rO0-6fE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d215a139-2474-4215-ac8a-476ee72689f9"
      },
      "source": [
        "print('Inicialización de parámetros de redes neuronales...')\n",
        "\n",
        "initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size)\n",
        "initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels)\n",
        "\n",
        "# Los parametros ininciales son puestos en una sola dimensión\n",
        "initial_nn_params = np.concatenate([initial_Theta1.ravel(), initial_Theta2.ravel()], axis=0)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicialización de parámetros de redes neuronales...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo es aplicado al dataset, con los pasos previamente definidos y se obtienen los valores que permitirán hacer predicciones"
      ],
      "metadata": {
        "id": "Flw7GMhEF8yY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ysYL_hX_D0k"
      },
      "source": [
        "#lambda se define al igual que el numero de veces que se optimizará\n",
        "lambda_ = 0.01\n",
        "max_iterations = 200\n",
        "\n",
        "# La funcion de costo es aplicada al modelo\n",
        "costFunction = lambda p: nnCostFunction(p, input_layer_size,\n",
        "                                        hidden_layer_size,\n",
        "                                        num_labels, X, y, lambda_)\n",
        "\n",
        "#funcion que permite minimizar la funcion de costo\n",
        "res = optimize.minimize(costFunction,\n",
        "                        initial_nn_params,\n",
        "                        jac=True,\n",
        "                        method='L-BFGS-B',  # Cambio de metodo 'L-BFGS-B', para poder definir las iteraciones\n",
        "                        options={'maxiter': max_iterations})\n",
        "# se obtienen los valores\n",
        "nn_params = res.x\n",
        "\n",
        "# Theta1  y Theta2 obtienen su forma inicial\n",
        "Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n",
        "                    (hidden_layer_size, (input_layer_size + 1)))\n",
        "\n",
        "Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n",
        "                    (num_labels, (hidden_layer_size + 1)))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prueba del modelo\n",
        "Ahora que tenemos los valores de theta, es que se pueden hacer las predicciones"
      ],
      "metadata": {
        "id": "UJgQexmhG_kY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDnQrQM4_0Ct"
      },
      "source": [
        "def predict(Theta1, Theta2, X):\n",
        "\n",
        "\n",
        "    m = X.shape[0]\n",
        "    num_labels = Theta2.shape[0]\n",
        "\n",
        "    p = np.zeros(m)\n",
        "    h1 = sigmoid(np.dot(np.concatenate([np.ones((m, 1)), X], axis=1), Theta1.T))\n",
        "    h2 = sigmoid(np.dot(np.concatenate([np.ones((m, 1)), h1], axis=1), Theta2.T))\n",
        "    p = np.argmax(h2, axis=1)\n",
        "    return p"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicción para los datos del entrenamiento**"
      ],
      "metadata": {
        "id": "gE0kWJP8HG-H"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxMinI1Y_6AG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82cadc92-f923-4dbe-8456-87876bb93c59"
      },
      "source": [
        "pred = predict(Theta1, Theta2, X[:,:])\n",
        "print(pred)\n",
        "print('Training Set Accuracy: %f' % (np.mean(pred == y[:]) * 100))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 ... 0 0 0]\n",
            "Training Set Accuracy: 81.393257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los datos de prueba de son normalizados para que estén en una misma escala"
      ],
      "metadata": {
        "id": "IshJKcuhHNCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def  testNormalize(X, mu, sigma):\n",
        "    X_norm = X.copy()\n",
        "    X_norm = (X - mu) / sigma\n",
        "    m, n = X_norm.shape\n",
        "    return X_norm"
      ],
      "metadata": {
        "id": "ctwbFZMX6gWB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_norm = testNormalize(Xp, mu, sigma)"
      ],
      "metadata": {
        "id": "PQnBfo5s6kxA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicción para los datos de prueba**"
      ],
      "metadata": {
        "id": "Fu_9A3SOHcoz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qrmea3i_hip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cb184a6-c17f-4d59-b74b-68294649fef1"
      },
      "source": [
        "pred = predict(Theta1, Theta2, X_test_norm[:,:])\n",
        "print(pred)\n",
        "print('Training Set Accuracy: %f' % (np.mean(pred == yp[:]) * 100))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 2 2 2]\n",
            "Training Set Accuracy: 60.571247\n"
          ]
        }
      ]
    }
  ]
}