# -*- coding: utf-8 -*-
"""BikeSharingRegression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZEQwDlfsgFVStBjA_SDPy0l0Tik5RxAN

**DATASET**


**Información general**

El siguiente dataset consiste en datos recolectados sobre el sistema utilizado para compartir bicicletas dentro de una ciudad entre los años 2011 y 2012, posee datos por hora.
El sistema para compartir bicicletas es una forma más moderna de rentar bicicletas en lugares determinados dentro de una ciudad. Estos datos son relevantes, ya que ayudan a medir de alguna forma el movimiento de una ciudad.

**ENLACE**:https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset

**Features**

Para facilitar el análisis con los cuadernillos dados en clases es que se ha modificado algunos features, específicamente se han eliminado los 10 primeros. Los cuales contaban con datos de tipo clasificación; los datos usados del dataset original son los siguientes:

   

*    x1: Temperatura en Celsius normalizada. Para su normalización se utilizó; la temperatura mínima registrada en una hora y la máxima, la fórmula;  (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39
*    x2: Sensación real de la temperatura en Celsius; derivan de la fórmula (t-t_min)/(t_max-t_min), t_min=-16, t_max=+50
*    x3: Humedad, los valores están divididos entre 100
*    x4: Velocidad del viento, los valores están divididos entre 67
*    x5: Cuenta casual de usuarios
*    x6: Cuenta de usuarios registrados

**Target**

*    y: correspone al total de usuarios por hora


**APLICACION DE LOS CUADERNILLOS**

# REGRESION LINEAL MULTIVARIABLE

**Librerias necesarias:**
"""

from google.colab import drive
drive.mount("/content/gdrive")

# Commented out IPython magic to ensure Python compatibility.
import os

import numpy as np

from matplotlib import pyplot
from mpl_toolkits.mplot3d import Axes3D

# %matplotlib inline

"""Una vez que las libreias han sido cargas es que se procede con cargar los datos provinientes del archivo, el cual venía en .csv, pero para facilitar su manipulación es que se convirtió en .txt, estando los datos separados por comas."""

data = np.loadtxt('/content/gdrive/MyDrive/Machine learning/Datasets/bicicletas_hora.txt', delimiter=',')
X = data[:, :6]
y = data[:, 6]
m = y.size
print(m)

print('{:>8s}{:>8s}{:>8s}{:>8s}{:>8s}{:>8s}{:>10s}'.format('X[:,0]', 'X[:, 1]', 'X[:, 2]','X[:, 3]','X[:, 4]','X[:, 5]','y'))
print('-'*80)
for i in range(10):
    print('{:8.0f}{:8.0f}{:8.0f}{:8.0f}{:8.0f}{:8.0f}{:10.0f}'.format(X[i, 0], X[i, 1], X[i, 2], X[i, 3], X[i, 4], X[i, 5],y[i]))

"""Una vez que los datos están cargados y se puede apreciar una pequeña parte de ellos es que se procede con la normalización de los datos utilizando la media y la varianza de cada feature"""

def  featureNormalize(X):
    X_norm = X.copy()
    mu = np.zeros(X.shape[1])
    sigma = np.zeros(X.shape[1])

    mu = np.mean(X, axis = 0)
    sigma = np.std(X, axis = 0)
    X_norm = (X - mu) / sigma

    return X_norm, mu, sigma

"""Una vez que se tiene la función es que la llama con los datos de los features y también podemos ver los valores calculados"""

X_norm, mu, sigma = featureNormalize(X)

print(X)
print('Media calculada:', mu)
print('Desviación estandar calculada:', sigma)
print(X_norm)

"""Una vez que la función cumple los valores es que se procede a añadir los valores de x0, el cual consiste en una columna de 1's"""

X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)

"""Para visualizar la nueva columna añadida:"""

print(X)

"""Ahora nuestros datos están listos para comenzar a buscar los thetas que nos permitan hacer predicciones para cualquier tipo de datos, primero se trabaja con la Función de Costo para muchos features, la cual consiste en el valor predicho menos el valor real de "y"


"""

def computeCostMulti(X, y, theta):
    m = y.shape[0]
    J = 0
    h = np.dot(X, theta)
    J = (1/(2 * m)) * np.sum(np.square(np.dot(X, theta) - y))
    return J

"""La función de costo que acaba de ser creada será utilizada dentro de la función de descenso de gradiente la cual tiene como función buscar el menor valor posible la función de costo. Durante la ejecución se irán encontrando varios valores los cuales serán actualizados hasta que sean mínimos"""

def gradientDescentMulti(X, y, theta, alpha, num_iters):

    m = y.shape[0]


    theta = theta.copy()

    J_history = []

    for i in range(num_iters):
        theta = theta - (alpha / m) * (np.dot(X, theta) - y).dot(X)
        J_history.append(computeCostMulti(X, y, theta))

    return theta, J_history

"""Ahora que ambas funciones han sido declaradas, es que comiezan a ser aplicadas en nuestro dataset, primero se debe defirnir el coeficiente alfa, el cual tras varias pruebas se determinó que el más conveniente para el caso y que ayuda a encontrar los valores de theta más rapido es alpha = 0.003 el numero de iteraciones también se definió como 5000 por que se encuentra un mínimo local con dicho par de datos, también theta es inicializado y el descenso de gradiente con los valores predefinidos, se puede observar la convergencia de costo con el mínimo local encontrado"""

alpha = 0.003
num_iters = 5000

"""Inicializa theta con la cantidad de columnas necesarias para el caso, en este 7, también se llama la función de descenso de gradiente con los datos anteriormente descritos"""

theta = np.zeros(7)
theta, J_history = gradientDescentMulti(X, y, theta, alpha, num_iters)

"""# Gráfico de Costo Multivariable
Podemos visuailizar la función de costo, se aprecia como la función de costo va tomando cada vez valores más pequeños
"""

pyplot.plot(np.arange(len(J_history)), J_history, lw=2)
pyplot.xlabel('Numero de iteraciones')
pyplot.ylabel('Costo J')

"""Los valores de theta obtenidos de la función de descenso de gradiente ya pueden ser visualizadas"""

print('theta calculado por el descenso por el gradiente: {:s}'.format(str(theta)))

"""# Predicciones Multivariable

**1 . Predicción para una hora con las características:**

*   x1(temperatura en Celsius normalizada): 0.56
*  x2(Sensasión real en Celsius normalizada): 0.5687
*  x3(Humedad/100): 0.54
*  x4(Velocidad del viento): 0.4179
*  x5(Usuarios casuales): 25
*  x6(Usuarios registrados): 6
"""

X_array = np.array([1, 0.56, 0.5687, 0.54, 0.4179,25, 6])
X_array[1:7] = (X_array[1:7] - mu) / sigma
price = np.dot(X_array, theta)

print('La cantidad de usuarios predecida con las características dichas (usando el descenso por el gradiente): {:.0f} usuarios'.format(price))

"""
**2 . Predicción para una hora con las características:**

*   x1(temperatura en Celsius normalizada): 0.48
*  x2(Sensasión real en Celsius normalizada): 0.4935
*  x3(Humedad/100): 0.2
*  x4(Velocidad del viento): 0.3214
*  x5(Usuarios casuales): 7
*  x6(Usuarios registrados): 12

"""

X_array = np.array([1, 0.48, 0.4935, 0.2, 0.3214, 7, 12])
X_array[1:7] = (X_array[1:7] - mu) / sigma
price = np.dot(X_array, theta)

print('La cantidad de usuarios predecida con las características dichas (usando el descenso por el gradiente): {:.0f} usuarios'.format(price))

"""**3 . Predicción para una hora con las características:**

*   x1(temperatura en Celsius normalizada): 0.76
*  x2(Sensasión real en Celsius normalizada): 0.7546
*  x3(Humedad/100): 0.78
*  x4(Velocidad del viento): 0.2354
*  x5(Usuarios casuales): 8
*  x6(Usuarios registrados): 21
"""

X_array = np.array([1, 0.76, 0.7546, 0.78 ,0.2354, 8, 21])
X_array[1:7] = (X_array[1:7] - mu) / sigma
price = np.dot(X_array, theta)

print('La cantidad de usuarios predecida con las características dichas (usando el descenso por el gradiente): {:.0f} usuarios'.format(price))

"""
**4 . Predicción para una hora con las características:**

*   x1(temperatura en Celsius normalizada): 0.42
*  x2(Sensasión real en Celsius normalizada): 0.4398
*  x3(Humedad/100): 0.64
*  x4(Velocidad del viento): 0.3287
*  x5(Usuarios casuales): 5
*  x6(Usuarios registrados): 24"""

X_array = np.array([1, 0.42,0.4398,0.64,0.3287,5,24])
X_array[1:7] = (X_array[1:7] - mu) / sigma
price = np.dot(X_array, theta)

print('La cantidad de usuarios predecida con las características dichas (usando el descenso por el gradiente): {:.0f} usuarios'.format(price))

"""**5 . Predicción para una hora con las características:**

*   x1(temperatura en Celsius normalizada): 0.55
*  x2(Sensasión real en Celsius normalizada): 0.5678
*  x3(Humedad/100): 0.32
*  x4(Velocidad del viento): 0.1287
*  x5(Usuarios casuales): 13
*  x6(Usuarios registrados): 17
"""

X_array = np.array([1, 0.55,0.5678,0.32,0.1287,13,17])
X_array[1:7] = (X_array[1:7] - mu) / sigma
price = np.dot(X_array, theta)

print('La cantidad de usuarios predecida con las características dichas (usando el descenso por el gradiente): {:.0f} usuarios'.format(price))

"""**6 . Predicción para una hora con las características:**

*   x1(temperatura en Celsius normalizada): 0.23
*  x2(Sensasión real en Celsius normalizada): 0.2299
*  x3(Humedad/100): 0.89
*  x4(Velocidad del viento): 0.102
*  x5(Usuarios casuales): 22
*  x6(Usuarios registrados): 19
"""

X_array = np.array([1, 0.23,0.2299,0.89,0.102,22,19])
X_array[1:7] = (X_array[1:7] - mu) / sigma
price = np.dot(X_array, theta)

print('La cantidad de usuarios predecida con las características dichas (usando el descenso por el gradiente): {:.0f} usuarios'.format(price))

"""**7 . Predicción para una hora con las características:**

*   x1(temperatura en Celsius normalizada): 0.31
*  x2(Sensasión real en Celsius normalizada): 0.3124
*  x3(Humedad/100): 0.75
*  x4(Velocidad del viento): 0.3881
*  x5(Usuarios casuales): 12
*  x6(Usuarios registrados): 10
"""

X_array = np.array([1, 0.31,0.3124,0.75,0.3881,12,10])
X_array[1:7] = (X_array[1:7] - mu) / sigma
price = np.dot(X_array, theta)

print('La cantidad de usuarios predecida con las características dichas (usando el descenso por el gradiente): {:.0f} usuarios'.format(price))

"""**8 . Predicción para una hora con las características:**

*   x1(temperatura en Celsius normalizada): 0.11
*  x2(Sensasión real en Celsius normalizada): 0.1197
*  x3(Humedad/100): 0.66
*  x4(Velocidad del viento): 0.1024
*  x5(Usuarios casuales): 18
*  x6(Usuarios registrados): 8
"""

X_array = np.array([1, 0.11,0.1197,0.66,0.1024,18,8])
X_array[1:7] = (X_array[1:7] - mu) / sigma
price = np.dot(X_array, theta)

print('La cantidad de usuarios predecida con las características dichas (usando el descenso por el gradiente): {:.0f} usuarios'.format(price))

"""**9 . Predicción para una hora con las características:**

*   x1(temperatura en Celsius normalizada): 0.99
*  x2(Sensasión real en Celsius normalizada): 0.9875
*  x3(Humedad/100): 0.27
*  x4(Velocidad del viento): 0.1642
*  x5(Usuarios casuales): 17
*  x6(Usuarios registrados): 9
"""

X_array = np.array([1, 0.99,0.9875,0.27,0.1642,17,9])
X_array[1:7] = (X_array[1:7] - mu) / sigma
price = np.dot(X_array, theta)

print('La cantidad de usuarios predecida con las características dichas (usando el descenso por el gradiente): {:.0f} usuarios'.format(price))

"""**10 . Predicción para una hora con las características:**

*   x1(temperatura en Celsius normalizada): 0.65
*  x2(Sensasión real en Celsius normalizada): 0.6611
*  x3(Humedad/100): 0.88
*  x4(Velocidad del viento): 0.3881
*  x5(Usuarios casuales): 13
*  x6(Usuarios registrados): 11
"""

X_array = np.array([1, 0.65,0.6611,0.88,0.3881,13,11])
X_array[1:7] = (X_array[1:7] - mu) / sigma
price = np.dot(X_array, theta)

print('La cantidad de usuarios predecida con las características dichas (usando el descenso por el gradiente): {:.0f} usuarios'.format(price))

"""# Ecuación Normal

Calcula directamente los valores de theta sin necesitar de tantas iteraciones como lo es con método del descens de gradiente.

Los datos son cargados nuevamente
"""

data = np.loadtxt('/content/gdrive/MyDrive/Machine learning/Datasets/bicicletas_hora.txt', delimiter=',')
X = data[:, :6]
y = data[:, 6]
m = y.size
print(m)
X = np.concatenate([np.ones((m, 1)), X], axis=1)

"""Dicha función viene ya definida por la fórmula"""

def normalEqn(X, y):
    theta = np.zeros(X.shape[1])
    theta = np.dot(np.dot(np.linalg.inv(np.dot(X.T,X)),X.T),y)
    return theta

"""La función anterior es llamada y theta adquiere sus valores"""

theta = normalEqn(X, y);
print('Theta calculado a partir de la ecuación de la normal: {:s}'.format(str(theta)));

"""# Predicciones Ecuación Normal

Con los datos de theta también se puede comenzar a hacer las predicciones, en este caso no es necesario normalizar el array que contiene los features

**1 . Predicción para una hora con las características:**

*   x1(temperatura en Celsius normalizada): 0.56
*  x2(Sensasión real en Celsius normalizada): 0.5687
*  x3(Humedad/100): 0.54
*  x4(Velocidad del viento): 0.4179
*  x5(Usuarios casuales): 25
*  x6(Usuarios registrados): 6
"""

X_array = [1, 0.56, 0.5687, 0.54, 0.4179,25, 6]
price = np.dot(X_array, theta)

print('La cantidad de usuarios predecida con las características dichas (usando el descenso por el gradiente): {:.0f} usuarios'.format(price))

"""**2 . Predicción para una hora con las características:**

*   x1(temperatura en Celsius normalizada): 0.48
*  x2(Sensasión real en Celsius normalizada): 0.4935
*  x3(Humedad/100): 0.2
*  x4(Velocidad del viento): 0.3214
*  x5(Usuarios casuales): 7
*  x6(Usuarios registrados): 12
"""

X_array = [1, 0.48, 0.4935, 0.2, 0.3214, 7, 12]
price = np.dot(X_array, theta)

print('La cantidad de usuarios predecida con las características dichas (usando el descenso por el gradiente): {:.0f} usuarios'.format(price))

"""**3 . Predicción para una hora con las características:**

*   x1(temperatura en Celsius normalizada): 0.76
*  x2(Sensasión real en Celsius normalizada): 0.7546
*  x3(Humedad/100): 0.78
*  x4(Velocidad del viento): 0.2354
*  x5(Usuarios casuales): 8
*  x6(Usuarios registrados): 21
"""

X_array = [1, 0.76, 0.7546, 0.78 ,0.2354, 8, 21]
price = np.dot(X_array, theta)

print('La cantidad de usuarios predecida con las características dichas (usando el descenso por el gradiente): {:.0f} usuarios'.format(price))

"""# Regresión polinómica

El comportamiento de los datos puede ser no lineal, por lo que es recomendable aplicar regresión polinómica

Se cargan los datos
"""

data = np.loadtxt('/content/gdrive/MyDrive/Machine learning/Datasets/bicicletas_hora.txt', delimiter=",")
X = data[:, :6]
y = data[:, 6]
m = y.size

print('-'*70)
for i in range(10):
     print('{:8.0f}{:8.0f}{:8.0f}{:8.0f}{:8.0f}{:8.0f}{:10.0f}'.format(X[i, 0], X[i, 1], X[i, 2], X[i, 3], X[i, 4], X[i, 5],y[i]))

"""Se puede graficar los datos"""

def plotData(x, y):
    fig = pyplot.figure()

    pyplot.plot(x, y, 'ro', ms=2, mec='k')
    pyplot.ylabel('Usuarios finales de bicis')
    pyplot.xlabel('Varios factores')

plotData(X, y)

"""Los datos se elevan al cuadrado para darle un comportamiento de parábola"""

X = np.concatenate([X, X * X], axis=1)

"""Nuevamente los datos son normalizados con su media y sigma, respectivamente"""

def  featureNormalize(X):
    X_norm = X.copy()
    mu = np.zeros(X.shape[1])
    sigma = np.zeros(X.shape[1])

    mu = np.mean(X, axis = 0)
    sigma = np.std(X, axis = 0)
    X_norm = (X - mu) / sigma

    return X_norm, mu, sigma

X_norm, mu, sigma = featureNormalize(X)

print(X)
print('Media calculada:', mu)
print('Desviación estandar calculada:', sigma)
print(X_norm)

plotData(X_norm, y)

"""Se añade x0"""

X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)

"""**Descenso por el Gradiente Polinómico**"""

def computeCostMulti(X, y, theta):
    m = y.shape[0]

    J = 0

    h = np.dot(X, theta)

    J = (1/(2 * m)) * np.sum(np.square(np.dot(X, theta) - y))

    return J

def gradientDescentMulti(X, y, theta, alpha, num_iters):

    m = y.shape[0]
    theta = theta.copy()
    J_history = []

    for i in range(num_iters):
        theta = theta - (alpha / m) * (np.dot(X, theta) - y).dot(X)
        J_history.append(computeCostMulti(X, y, theta))

    return theta, J_history

"""# Gráfico de Costo Polinómica
Ahora se procede a aplicar las funciones en los datos y obtener el gráfico de la función de la normal
"""

alpha = 0.001
num_iters = 8000

theta = np.zeros(13)
theta, J_history = gradientDescentMulti(X, y, theta, alpha, num_iters)


pyplot.plot(np.arange(len(J_history)), J_history, lw=2)
pyplot.xlabel('Numero de iteraciones')
pyplot.ylabel('Costo J')


print('theta calculado por el descenso por el gradiente: {:s}'.format(str(theta)))