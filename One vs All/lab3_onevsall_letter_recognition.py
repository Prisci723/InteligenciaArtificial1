# -*- coding: utf-8 -*-
"""Lab3 OnevsAll Letter Recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17r9QuvZ9_ApuDOEM2BEgb_rpEqcN-hKM

# Clasificación multiclase
El siguiente dataset tiene como propósito entrenar de regresión logística (clasificación multiclase) utilizando el cuadernillo que avanzamos en clases, one vs. all.

# Dataset
El siguiente dataset posee de los datos relacionados a la identificación de las letras mayúsculas del alfabeto ingés.

El siguiente dataset está compuesto por 16 features los cuales son:
* x1: posicion de la x
* x2: posicion en y
* x3: ancho del cuadrado
* x4: altura del cuadrado
* x5: total de pixeles
* x6: media de los pixeles en x
* x7: media de los pixeles en y
* x8: varianza de x
* x9: varianza de y
* x10: varianza de la correlación de xy
* x11: media de x*x*y
* x12: media de x*y*y
* x13: media del borde contado de izquierda a derecha
* x14: correlacion del eje x con y
* x15: media del borde de y del fondo al tope
* x16: correlacion del eje y con x


y el target:
* y: que letra es (A-Z)

El dataset fue obtenido de la página:
https://archive.ics.uci.edu/dataset/59/letter+recognition

# Tratamiento con pandas
Como se puede observar el dataset viene en un archivo .csv por defecto el cual posee directamente todos los valores de los features con el target correspondiente, sin tener etiquetas en las columnas, por lo que manualmente, para facilitar el tratamiento es que se añadió una fila con los nombres de cada una.
También se puede comprobar que los datos están completos y no requieren de un tratamiento profundo, simplemente el target, el cual posee datos de tipo caracter, por lo que se procede a cambiar las letras por numeros.
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
from sklearn.preprocessing import OrdinalEncoder
#pandas para tratar los datos y OrdinalEncoder para transformar los caracteres en numeros

dataframe = pd.read_csv("/content/drive/MyDrive/Machine learning/Datasets/letter_regonition.csv", sep=",")
print(dataframe)

"""Una vez que las librerías han sido cargadas, es que se procede a utilizarlas, lo que ocurre es que la columna de target 'y', los caracteres serán reemplazados por numeros de forma ordenada, es decir, que se tendrá el siguiente resultado.



*   A --> 0
*   B --> 1
*  C --> 2
* D --> 3
* E --> 4
* E --> 4
* F --> 5
* G --> 6
* H --> 7
* I --> 8
* J --> 9
* K --> 10
* L --> 11
* M  --> 12
* N --> 13
* O  --> 14
* P  --> 15
* Q  --> 16
* R  --> 17
* S  --> 18
* T  --> 19
* U  --> 20
* V  --> 21
* W  --> 22
* X  --> 23
* Y  --> 24
* Z --> 25





"""

enc = OrdinalEncoder()
dataframe['y'] = enc.fit_transform(dataframe[['y']])
print(dataframe)

"""Podemos comprobar que los datos de y, target, ahora son numericos y sevirán para ser aplicados dentro del código"""

dataframe['y'].unique()

"""Procedemos a guardar el archivo modificado"""

dataframe.to_csv("letter_recognition.csv")

"""# Aplicacion de one vs all

El siguiente codigo tiene como objetivo entrenar con los datos correspondientes del dataset, aplicado al codigo de one vs all, el cual consiste en que los datos son separados utilizando clasificadores binarios según cada clase que exista, haciendo que cada clase se distinga de las demás. Al final se obiente la predicción de a que clase pertenece un determinada entrada de X.
"""

# Commented out IPython magic to ensure Python compatibility.
import os

import numpy as np

from matplotlib import pyplot

from scipy import optimize

# %matplotlib inline

"""El dataset posee 20000 datos los cuales el 80% es decir 16000 datos serán destinados al entrenamiento. 4000 datos para la pruba."""

# 17 elementos contando x0
input_layer_size  = 17
# de 0 a 25
num_labels = 26

#Se carga el dataset
data = np.loadtxt('/content/drive/MyDrive/Machine learning/Datasets/Clean_letter_recognition.csv', delimiter=',')

Y = data[:, 0]  # Primera columna
X = data[:, 1:]  # Resto de las columnas
# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, y_train = X[:16000], Y[:16000]
X_test, y_test = X[16000:], Y[16000:]
X = X_train
Y = y_train

m = Y.size

print(X)
print(Y)

print(X_test)
print(y_test)

"""**Normalización de los datos**

Los datos deben ser normalizados para estar dentro de la misma escala, la forma con la que se normalizan los datos es utilizando la media y sigma.
"""

def  featureNormalize(X):
    X_norm = X.copy()
    mu = np.zeros(X.shape[1])
    sigma = np.zeros(X.shape[1])

    mu = np.mean(X, axis = 0)
    sigma = np.std(X, axis = 0)
    X_norm = (X - mu) / sigma

    return X_norm, mu, sigma

X_norm, mu, sigma = featureNormalize(X)

"""X es asignada con los valores normalizados"""

m, n = X.shape
X = X_norm

"""**Definicion de la funcion de la sigmoide**

La sigmoide es utilizada para colocar cualquier valor dentro de un rango de 0 y 1, el cual servirá como resultado para calcular las probabilidades de cada clase.
"""

def sigmoid(z):
    return 1.0 / (1.0 + np.exp(-z))

"""**Calculo de la funcion de cosoo y gradiente para regresión logística**

El objetivo es encontrar los valores más óptimos para cada theta.

Una vez que la funcion sea ejecutada se contará con los valores optimizados de theta.
"""

def lrCostFunction(theta, X, y, lambda_):
    m = y.size

    if y.dtype == bool:
        y = y.astype(int)

    J = 0
    grad = np.zeros(theta.shape)

    h = sigmoid(X.dot(theta.T))

    temp = theta
    temp[0] = 0
    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))

    grad = (1 / m) * (h - y).dot(X)
    grad = grad + (lambda_ / m) * temp

    return J, grad

"""**Función one vs all**

En esta función es donde se entrenerá a las clases, de forma individual cada clase será entrenada para distinguirse de las demás clases.
"""

def oneVsAll(X, y, num_labels, lambda_):
    m, n = X.shape

    all_theta = np.zeros((num_labels, n+1))

    X = np.concatenate([np.ones((m, 1)), X], axis=1)

    for c in np.arange(num_labels):
        initial_theta = np.zeros(n+1)
        options = {'maxiter': 50}
        res = optimize.minimize(lrCostFunction,
                                initial_theta,
                                (X, (y == c), lambda_),
                                jac=True,
                                method='CG',
                                options=options)

        all_theta[c] = res.x

    return all_theta

print(X.shape)

lambda_ = 0.1
all_theta = oneVsAll(X, Y, num_labels, lambda_)
print(all_theta.shape)

print(all_theta)

"""# Predicciones

Con las funciones anteriores es que ya tenemos los valores de theta que servirán para las prediciciones, al igual que los valores normalizados de X

**Funcion para predecir one vs all**

Para cada ejemplo en X la función calculará la probabilidad de que el ejemplo pertenezca a una clase, esto ocurre gracias a aplicar la regresión logística a la hipótesis, el resultado es una prabilidad enrtre 0 y 1, después la función escogerá la clase a la que la probabilidad es más alta, siendo esta la clase la clase predecida.
"""

def predictOneVsAll(all_theta, X):

    m = X.shape[0];
    num_labels = all_theta.shape[0]

    p = np.zeros(m)

    # Add ones to the X data matrix
    X = np.concatenate([np.ones((m, 1)), X], axis=1)
    p = np.argmax(sigmoid(X.dot(all_theta.T)), axis = 1)

    return p

"""**Resultados del entrenamiento**

Ahora es que se llama a los valores destinados a mostar la prueba del entrenamiento, X_test y Y_test, mostrando también la precisión de los datos predecidos.

**Normalizacion de los valores de X_test**

Previo al entreanamiento los valores de X_test deben ser normalizados
"""

X_test_norm, mu_test, sigma_test = featureNormalize(X_test)

X_test = X_test_norm

"""Para visualizar los resultados es que solo se imprime las filas de 10 a 150"""

print(X_test.shape)
pred = predictOneVsAll(all_theta, X_test)
print('Precision del conjuto de entrenamiento: {:.2f}%'.format(np.mean(pred == y_test) * 100))
XPrueba = X_test.copy()
print(XPrueba.shape)

m, n = X_test.shape

XPrueba = np.concatenate([np.ones((m, 1)), XPrueba], axis=1)
print(XPrueba.shape)
p = np.argmax(sigmoid(XPrueba.dot(all_theta.T)), axis = 1)
print(p[10:150])


print(y_test[10:150])